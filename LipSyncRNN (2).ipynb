{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqP1uF8oPv1F"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe #if you run this script on colab you can install mediapipe by running this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Folder structure<br>\n",
        "<pre>\n",
        "video-----> <br>\n",
        "          '1.mp4' <br>\n",
        "          '2.mp4' <br>\n",
        "          '3.mp4' <br>\n",
        "           etc... <br>\n",
        "\n",
        "audio -----><br>\n",
        "          '1.wav' <br>\n",
        "          '2.wav' <br>\n",
        "          '3.wav' <br>\n",
        "          etc... <br>\n",
        "</pre>\n",
        "\n",
        "Here 1,2,3 are file names. you can name it anything you prefer.but make sure to have the exact same name to the corresponding audio file. All the files should be same fps and same duration.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vZjDHkjxsz7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Main Code - Run this to train the network\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "import math\n",
        "import joblib\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "vid_dir = input('path of video directory - ') #all videos should be same duration\n",
        "aud_dir = input('path of audio directory - ') #all audio clips should match the video duration and the name.Should be in wav format\n",
        "BatchSize = int(input('Batch size - '))\n",
        "hidden_dim = 468\n",
        "n_layers = 60   #this parameter defines how many rnn layers. research paper suggests 60\n",
        "length = 150    #This parameter corresponds to duration of the video.Number of frames per single clip. If you have longer clips you can have a igger value\n",
        "n_epochs = int(input('Epochs - '))\n",
        "lr=float(input('Learning Rate - '))\n",
        "\n",
        "vid_ids = [files for files in os.walk(vid_dir)] \n",
        "vid_ids = [filenames[:-4] for filenames in vid_ids[0][2] ]\n",
        "\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "mpFaceMesh = mp.solutions.face_mesh\n",
        "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n",
        "\n",
        "\n",
        "X_data = []\n",
        "Y_data = []\n",
        "Z_data = []\n",
        "aud = []\n",
        "\n",
        "for files in vid_ids:\n",
        "  video = vid_dir +'/'+files+'.mp4'\n",
        "  audio = aud_dir + '/' + files+'.wav'\n",
        "\n",
        "  cap = cv2.VideoCapture(video)  #reading the video\n",
        "  Fs,audio = wavfile.read(audio) #reading the audio\n",
        "  \n",
        "  #finding the fps\n",
        "  (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "  if int(major_ver)  < 3 :\n",
        "    fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "    #print (\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "  else :\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    #print (\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "  \n",
        "  #length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  \n",
        "  \n",
        "  #creating facepoints\n",
        "  for i in range(length):\n",
        "    success,img = cap.read()\n",
        "    results = faceMesh.process(img)\n",
        "    \n",
        "    if results.multi_face_landmarks:\n",
        "      tempx = []\n",
        "      tempy = []\n",
        "      tempz = []\n",
        "      for faceLms in results.multi_face_landmarks:\n",
        "        for lm in faceLms.landmark:\n",
        "          tempx.append(lm.x)\n",
        "          tempy.append(lm.y)\n",
        "          tempz.append(lm.z)\n",
        "\n",
        "    else:\n",
        "      tempx = []\n",
        "      tempy = []\n",
        "      tempz = []\n",
        "      for i in range(468):\n",
        "        tempx.append(0)\n",
        "        tempy.append(0)\n",
        "        tempz.append(0)\n",
        "          \n",
        "    X_data.append(tempx)  \n",
        "    Y_data.append(tempy)\n",
        "    Z_data.append(tempz)\n",
        "      \n",
        "    \n",
        "  cap.release()\n",
        "  \n",
        "  #creating audio\n",
        "  \n",
        "  aud = np.array(np.concatenate((aud, audio.T[0])))\n",
        "  #print(np.array(audio.T[0]).shape)\n",
        "\n",
        "#print(np.array(X_data).shape)\n",
        "time_per_frame_in_video = 1/fps #seconds 1/30\n",
        "time_per_frame_in_audio = time_per_frame_in_video * Fs\n",
        "sequences = time_per_frame_in_audio\n",
        "input_size = int(len(audio)/length)\n",
        "\n",
        "X_data = torch.tensor(X_data)\n",
        "Y_data = torch.tensor(Y_data)\n",
        "Z_data = torch.tensor(Z_data)\n",
        "aud = torch.tensor(aud)\n",
        "\n",
        "X_data = X_data.view( -1,BatchSize , length, 468)\n",
        "Y_data = Y_data.view( -1,BatchSize , length, 468)\n",
        "Z_data = Z_data.view( -1,BatchSize , length, 468)\n",
        "aud = aud[0:BatchSize*length*input_size].view(-1,BatchSize,length,input_size)\n",
        "number_of_batches = aud.size(dim = 0)\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fcx = nn.Linear(hidden_dim, output_size)\n",
        "        self.fcy = nn.Linear(hidden_dim, output_size)\n",
        "        self.fcz = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        outX = self.fcx(out)\n",
        "        outY = self.fcy(out)\n",
        "        outZ = self.fcz(out)\n",
        "\n",
        "        return outX, outY, outZ\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "\n",
        "model = Model(input_size,468,hidden_dim*3,60).to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "loss_vector = []\n",
        "\n",
        "for epoch in range(n_epochs): # 3 full passes over the data\n",
        "  #  model.train()\n",
        "    for data in range(number_of_batches):  # `data` is a batch of data\n",
        "        model.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
        "        outX,outY,outZ = model.forward(aud[data].to(device).float())  # pass in the reshaped batch (recall they are 28x28 atm)\n",
        "        \n",
        "        \n",
        "\n",
        "        lossX = loss_function(outX,X_data[data].to(device).float())\n",
        "        lossY = loss_function(outY,Y_data[data].to(device).float())\n",
        "        lossZ = loss_function(outZ,Z_data[data].to(device).float())\n",
        "        loss = lossX+lossY+lossZ\n",
        "\n",
        "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
        "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
        "    print(epoch,loss)\n",
        "    loss_vector.append(loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j5IEk-9PnjF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eab29e6-9450-4dff-ce1a-254e9c933399"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "path of video directory - /content/drive/MyDrive/Project Docments/lip sync/vid\n",
            "path of audio directory - /content/drive/MyDrive/Project Docments/lip sync/aud\n",
            "Batch size - 2\n",
            "Epochs - 2\n",
            "Learning Rate - 1\n",
            "0 tensor(0.3830, grad_fn=<AddBackward0>)\n",
            "1 tensor(21853.0938, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot loss\n",
        "Lv = [] \n",
        "for i in range(len(loss_vector)):\n",
        "    Lv.append(loss_vector[i].item())\n",
        "print(Lv)\n",
        "plt.plot(Lv)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "\n",
        "plt.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "KArlG6rm8WmP",
        "outputId": "1631f394-9d49-42e0-f900-305b352e3251"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3829939067363739, 21853.09375]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the model (This is optional, If you think you got good results you can save the model for later use)\n",
        "model.eval()\n",
        "location = input('Enter the location you would like to save this model/ the model name - ')\n",
        "#Enter the location you would like to save this model ---> this is the folder you are putting it\n",
        "#the model name ----> give any name you like\n",
        "joblib.dump(model, location)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1q64z10lrKX",
        "outputId": "a4794aae-3b78-4262-a1c5-39c9e4ed5fda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the location you would like to save this model - /content/drive/MyDrive/Project Docments/lip sync/train1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Project Docments/lip sync/train1']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title You can feed test audio here after training\n",
        "model.eval()\n",
        "test = input('audio file path - ')\n",
        "Fs,test = wavfile.read(test)\n",
        "l = math.floor(len(test.T[0])/input_size)\n",
        "test = torch.tensor(test.T[0])[:l*input_size].view(1,l,input_size).to(device)\n",
        "test_output = model(test.float())"
      ],
      "metadata": {
        "id": "1gWetB8KpsBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "hKk9_5BSovfF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}